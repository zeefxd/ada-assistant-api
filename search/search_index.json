{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Hey Ada \ud83d\ude80","text":"<p>Hey Ada is a smart, modern voice assistant for ESP32, featuring real-time speech recognition and natural language processing.</p>"},{"location":"#features","title":"\u2728 Features","text":"<ul> <li>\ud83c\udfa4 Speech-to-Text powered by Whisper.cpp</li> <li>\ud83d\udde3\ufe0f Text-to-Speech with XTTS-v2</li> <li>\ud83e\udd16 Natural Language Processing using Ollama</li> <li>\ud83d\uddd3\ufe0f Command Detection for calendar, reminders, and music</li> </ul>"},{"location":"#quick-links","title":"\ud83d\ude80 Quick Links","text":"<ul> <li>\ud83d\udee0\ufe0f Installation Guide</li> <li>\u2699\ufe0f Configuration</li> <li>\ud83c\udfa4 Speech To Text</li> <li>\ud83e\udde0 LLM Reference</li> <li>\ud83d\udd79\ufe0f Command Detector</li> <li>\ud83d\udde3\ufe0f Text To Speech</li> <li>\ud83e\udd1d Contribute to Hey Ada</li> </ul> <p>Tip: Explore the docs to unlock the full potential of Hey Ada on your ESP32!</p>"},{"location":"api/commands/","title":"\ud83d\ude80 Command Detection","text":"<p>The Command Detection module provides natural language command parsing for Hey Ada.</p>"},{"location":"api/commands/#supported-command-types","title":"\ud83c\udfaf Supported Command Types","text":"<p>Hey Ada understands a variety of command types:</p> \ud83c\udff7\ufe0f Command Type \ud83d\udcdd Description \ud83d\udcac Example <code>calendar</code> Create calendar events \"Utw\u00f3rz spotkanie jutro o 15:00\" <code>reminder</code> Set reminders \"Przypomnij mi o lekarzu o 17:00\" <code>music</code> Control music playback \"Odtw\u00f3rz utw\u00f3r \""},{"location":"api/commands/#how-it-works","title":"\u2699\ufe0f How It Works","text":"<p>The command detection workflow:</p> <ol> <li>Transcription: User speech is transcribed via the Speech-to-Text API.</li> <li>Analysis: The text is analyzed by the LLM and <code>CommandDetector</code> class.</li> <li>Pattern Matching: If a command pattern is detected, parameters are extracted.</li> <li>Response: A structured command object is returned to the client.</li> </ol>"},{"location":"api/commands/#command-object-structure","title":"\ud83e\udde9 Command Object Structure","text":"<p>Each recognized command includes:</p> <ul> <li>Type: (e.g., <code>calendar</code>, <code>reminder</code>, <code>music</code>)</li> <li>Parameters: Details specific to the command type</li> </ul>"},{"location":"api/llm/","title":"\ud83d\ude80 Language Model API","text":"<p>The Language Model component uses Ollama to provide natural language processing capabilities.</p>"},{"location":"api/llm/#api-endpoints","title":"\ud83d\udcda API Endpoints","text":""},{"location":"api/llm/#post-llmgenerate","title":"\ud83d\udd39 <code>POST /llm/generate</code>","text":"<p>Generate intelligent responses to user queries using a large language model.</p>"},{"location":"api/llm/#request-body","title":"\ud83d\udcdd Request Body","text":"<pre><code>{\n    \"prompt\": \"User query text\",\n    \"system_prompt\": \"Optional system instructions\",\n    \"temperature\": 0.7,\n    \"max_tokens\": 1024\n}\n</code></pre> Parameter Type Description <code>prompt</code> string The user's query or message <code>system_prompt</code> string (Optional) System instructions for the LLM <code>temperature</code> float Controls randomness (0.0\u20131.0, default: 0.7) <code>max_tokens</code> integer Maximum tokens to generate in the response (default: 1024)"},{"location":"api/llm/#example-response","title":"\ud83d\udfe2 Example Response","text":"<pre><code>{\n    \"response\": \"Generated text response\",\n    \"is_command\": false,\n    \"command_type\": null,\n    \"command_params\": null,\n    \"processing_time\": \"0.45s\"\n}\n</code></pre>"},{"location":"api/llm/#get-llminfo","title":"\ud83d\udd39 <code>GET /llm/info</code>","text":"<p>Retrieve information about the currently loaded language model.</p>"},{"location":"api/llm/#example-response_1","title":"\ud83d\udfe2 Example Response","text":"<pre><code>{\n    \"model\": \"gemma3:4b\",\n    \"status\": \"loaded\"\n}\n</code></pre>"},{"location":"api/llm/#command-detection-integration","title":"\ud83e\udde9 Command Detection Integration","text":"<p>The Language Model API seamlessly integrates with the Command Detection module to identify and process specific user commands within natural language queries.</p> <p>Tip: For best results, provide clear prompts and adjust the <code>temperature</code> parameter to fine-tune response creativity.</p>"},{"location":"api/stt/","title":"\ud83c\udfa4 Speech-to-Text API","text":"<p>The Speech-to-Text module uses Whisper.cpp to transcribe audio files. </p>"},{"location":"api/stt/#api-endpoints","title":"\ud83d\ude80 API Endpoints","text":""},{"location":"api/stt/#post-stttranscribe","title":"<code>POST /stt/transcribe</code>","text":"<p>Transcribe your audio files effortlessly and receive instant text results.</p>"},{"location":"api/stt/#request-parameters","title":"\ud83d\udce5 Request Parameters","text":"Name Type Description Example <code>file</code> File Audio file to transcribe (<code>.wav</code>, <code>.mp3</code>, etc.) <code>audio.wav</code> <code>language</code> String Language code (<code>\"auto\"</code> for auto-detect, <code>\"PL\"</code> for Polish, etc.) <code>\"auto\"</code> <code>use_json</code> Boolean If <code>true</code>, output will be formatted as JSON <code>true</code>"},{"location":"api/stt/#response","title":"\ud83d\udce4 Response","text":"<p>Returns a Server-Sent Events (SSE) stream with transcription segments as they become available.</p>"},{"location":"api/tts/","title":"\ud83d\udde3\ufe0f Text-to-Speech API","text":"<p>The Text-to-Speech module uses XTTS-v2 to generate natural-sounding Polish speech.</p>"},{"location":"api/tts/#api-endpoints","title":"\ud83d\ude80 API Endpoints","text":""},{"location":"api/tts/#post-ttssynthesize","title":"POST <code>/tts/synthesize</code>","text":"<p>Transform your Polish text into lifelike speech using a custom voice sample.</p>"},{"location":"api/tts/#request-body","title":"\ud83d\udce5 Request Body","text":"<pre><code>{\n    \"text\": \"Text to convert to speech\",\n    \"voice_sample\": \"polish_female_voice.wav\",\n    \"language\": \"pl\"\n}\n</code></pre> Parameter Type Description <code>text</code> string Text to convert to speech (Polish only) <code>voice_sample</code> string Reference voice sample filename (must be in the <code>assets</code> directory) <code>language</code> string Language code (default: <code>\"pl\"</code> for Polish)"},{"location":"api/tts/#response","title":"\ud83d\udce4 Response","text":"<ul> <li>Returns: An audio file (<code>.wav</code>) containing the synthesized speech.</li> </ul>"},{"location":"api/tts/#implementation-details","title":"\u2699\ufe0f Implementation Details","text":"<ul> <li>Loads the XTTS-v2 model on first use for efficient performance.</li> <li>Utilizes your provided voice sample for voice cloning.</li> <li>Synthesizes speech with the cloned voice profile for a personalized experience.</li> <li>Delivers the result as a downloadable audio file.</li> </ul> <p>Tip: For best results, use a clear, high-quality <code>.wav</code> voice sample in Polish.</p>"},{"location":"development/contributing/","title":"\ud83d\ude80 Contributing to Hey Ada","text":"<p>Thank you for your interest in making Hey Ada even better! We welcome all contributions\u2014whether it's fixing bugs, adding features, or improving documentation.</p>"},{"location":"development/contributing/#development-setup","title":"\ud83d\udee0\ufe0f Development Setup","text":"<p>Follow these steps to get your development environment ready:</p> <ol> <li> <p>Clone the Repository <pre><code>git clone https://github.com/zeefxd/ada-assistant-api.git\ncd ada-assistant-api\n</code></pre></p> </li> <li> <p>Set Up a Virtual Environment <pre><code>python -m venv venv\n</code></pre></p> <ul> <li>On Windows: <pre><code>venv\\Scripts\\activate\n</code></pre></li> <li>On Linux/macOS: <pre><code>source venv/bin/activate\n</code></pre></li> </ul> </li> <li> <p>Install Development Dependencies <pre><code>pip install -r requirements.txt\n</code></pre></p> </li> </ol>"},{"location":"development/contributing/#pull-request-process","title":"\ud83d\udce6 Pull Request Process","text":"<ol> <li>Fork the repository on GitHub.</li> <li>Create a new branch for your feature or bugfix.</li> <li>Make your changes and commit them with clear, descriptive messages.</li> <li>Push your branch to your fork.</li> <li>Open a Pull Request to the main repository.</li> </ol>"},{"location":"development/contributing/#tips-for-contributors","title":"\ud83d\udca1 Tips for Contributors","text":"<ul> <li>Write clear, concise commit messages.</li> <li>Add tests for new features or bug fixes when possible.</li> </ul> <p>Thank you for helping make Hey Ada awesome! \ud83d\ude4c</p>"},{"location":"getting-started/configuration/","title":"Configuration","text":""},{"location":"getting-started/configuration/#required-models","title":"\ud83d\ude80 Required Models","text":"<p>The application automatically downloads the following:</p> <ul> <li>Whisper.cpp <code>large-v3-turbo</code> model for speech recognition  </li> <li>FFmpeg (if not already installed)</li> </ul>"},{"location":"getting-started/configuration/#manual-dependency-setup","title":"\ud83d\udee0\ufe0f Manual Dependency Setup","text":"<p>If the automatic setup fails, you can manually install required dependencies:</p>"},{"location":"getting-started/configuration/#whispercpp","title":"Whisper.cpp","text":"<ol> <li> <p>Clone the Repository: <pre><code>git clone https://github.com/ggerganov/whisper.cpp.git /tmp/whisper.cpp-src\ncd /tmp/whisper.cpp-src\n</code></pre></p> </li> <li> <p>Build the Executable: <pre><code>make\n</code></pre>     &gt; \ud83d\udca1 For GPU acceleration (CUDA, OpenCL, etc.), see the official build guide.</p> </li> <li> <p>Copy the Executable: </p> <ul> <li>Create a <code>whisper.cpp</code> directory in your project root.</li> <li>Copy the built <code>whisper-cli.exe</code> into <code>whisper.cpp/</code>.</li> </ul> <pre><code>mkdir -p /your/project/path/whisper.cpp\ncp ./whisper-cli.exe /your/project/path/whisper.cpp/\n</code></pre> </li> <li> <p>Verify:     Ensure <code>whisper.cpp/whisper-cli.exe</code> exists in your project directory.</p> </li> </ol>"},{"location":"getting-started/configuration/#ffmpeg","title":"FFmpeg","text":"<p>If FFmpeg isn't installed automatically:</p> <ol> <li>Download FFmpeg from ffmpeg.org.</li> <li>Extract to: <pre><code>model/ffmpeg/\n</code></pre></li> <li>Ensure: <pre><code>model/ffmpeg/bin/ffmpeg.exe\n</code></pre>     exists.</li> </ol>"},{"location":"getting-started/configuration/#speech-recognition-stt-configuration","title":"\ud83d\udde3\ufe0f Speech Recognition (STT) Configuration","text":"<p>You can change the Whisper model in <code>stt.py</code>:</p> <pre><code># Change this to use a different model\nWHISPER_CPP_MODEL_NAME = \"large-v3-turbo-q8-v3\"\n</code></pre> <p>Available models:</p> <ul> <li><code>tiny</code>, <code>tiny.en</code></li> <li><code>base</code>, <code>base.en</code></li> <li><code>small</code>, <code>small.en</code></li> <li><code>medium</code>, <code>medium.en</code></li> <li><code>large-v1</code>, <code>large-v2</code>, <code>large-v3</code></li> </ul>"},{"location":"getting-started/configuration/#text-to-speech-tts-configuration","title":"\ud83d\udde8\ufe0f Text-to-Speech (TTS) Configuration","text":"<p>To use TTS with a Polish voice:</p> <ol> <li>Record or download a Polish female voice sample.</li> <li>Save as WAV in the <code>assets</code> directory.</li> <li>Reference the file in your API calls.</li> </ol>"},{"location":"getting-started/configuration/#command-detection","title":"\ud83d\udd79\ufe0f Command Detection","text":"<p>The system recognizes commands like:</p> <ul> <li>Calendar events</li> <li>Reminders</li> <li>Music controls</li> </ul> <p>Customize these by editing <code>command_detector.py</code>.</p>"},{"location":"getting-started/installation/","title":"\ud83d\ude80 Installation Guide","text":"<p>Welcome! Follow these steps to get your project up and running.</p>"},{"location":"getting-started/installation/#prerequisites","title":"\ud83d\udee0\ufe0f Prerequisites","text":"<p>Ensure you have the following installed:</p> <ul> <li>Python <code>3.8+</code></li> <li>FFmpeg <sub>(auto-installed if missing)</sub></li> <li>CUDA-compatible GPU <sub>(optional, for enhanced performance)</sub></li> </ul>"},{"location":"getting-started/installation/#quick-start","title":"\u26a1 Quick Start","text":"<ol> <li> <p>Clone the Repository <pre><code>git clone https://github.com/zeefxd/ada-assistant-api.git .\n</code></pre></p> </li> <li> <p>Install Dependencies <pre><code>pip install -r requirements.txt\n</code></pre></p> </li> <li> <p>Launch the Application <pre><code>uvicorn main:app\n</code></pre></p> </li> </ol> <p>\ud83c\udf10 The server will be available at: http://localhost:8000</p>"}]}